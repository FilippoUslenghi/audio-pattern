{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.ndarray size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/__init__.py:29\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     np_version_under1p17 \u001b[38;5;28;01mas\u001b[39;00m _np_version_under1p17,\n\u001b[1;32m     24\u001b[0m     np_version_under1p18 \u001b[38;5;28;01mas\u001b[39;00m _np_version_under1p18,\n\u001b[1;32m     25\u001b[0m     is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev,\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hashtable \u001b[38;5;28;01mas\u001b[39;00m _hashtable, lib \u001b[38;5;28;01mas\u001b[39;00m _lib, tslib \u001b[38;5;28;01mas\u001b[39;00m _tslib\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# hack but overkill to use re\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot import name \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/_libs/__init__.py:13\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaTType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterval\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m ]\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     NaT,\n\u001b[1;32m     16\u001b[0m     NaTType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     iNaT,\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32mpandas/_libs/interval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.ndarray size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import scienceplots\n",
    "\n",
    "plt.style.use(\"science\")\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ESC-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "data_dir = \"ESC-50-master\"\n",
    "df = pd.read_csv(os.path.join(data_dir, \"meta\", \"esc50.csv\"))\n",
    "df = df.query(\"esc10 == True\").reset_index()\n",
    "\n",
    "categories = df[\"category\"].to_numpy()\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "target = encoder.fit_transform(categories.reshape(-1, 1)).toarray()\n",
    "df[\"target\"] = target.tolist()\n",
    "df[\"class\"] = df[\"target\"].apply(lambda x: np.argmax(x))\n",
    "\n",
    "df[[\"category\", \"class\"]].drop_duplicates().set_index(\"class\").sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "g = sns.histplot(df, x=\"class\", discrete=True, shrink=0.6)\n",
    "plt.title(\"Class balance\")\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.xticks(np.arange(10))\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "plt.savefig(os.path.join(\"images\", \"class_balance.png\"), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "\n",
    "class myPipeline(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_mfcc: int = 40,\n",
    "        sample_rate=44100,\n",
    "        mtWin=1,\n",
    "        mtStep=0.5,\n",
    "        stWin=0.02,\n",
    "        stStep=0.01,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.sample_rate = sample_rate\n",
    "        self.mtWin = np.floor(mtWin * sample_rate).astype(int)\n",
    "        self.mtStep = np.floor(mtStep * sample_rate).astype(int)\n",
    "        self.stWin = np.floor(stWin * sample_rate).astype(int)\n",
    "        self.stStep = np.floor(stStep * sample_rate).astype(int)\n",
    "\n",
    "        self.resample = torchaudio.transforms.Resample(\n",
    "            new_freq=self.sample_rate, lowpass_filter_width=128\n",
    "        )\n",
    "\n",
    "        self.mfcc = torchaudio.transforms.MFCC(\n",
    "            sample_rate=self.sample_rate,\n",
    "            n_mfcc=self.n_mfcc,\n",
    "            melkwargs={\"n_fft\": 2048, \"hop_length\": 512},\n",
    "            log_mels=True,\n",
    "        )\n",
    "\n",
    "    def stereo2mono(self, waveform: torch.Tensor) -> torch.Tensor:\n",
    "        if waveform.shape[0] == 2:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "        return waveform\n",
    "\n",
    "    def windowize(self, waveform: torch.Tensor, win: int, step: int) -> torch.Tensor:\n",
    "        mtWindows = waveform.unfold(1, win, step)\n",
    "        return mtWindows\n",
    "\n",
    "    def timeFeatExtraction(self, waveform: torch.Tensor) -> tuple[\n",
    "        torch.Tensor,\n",
    "        torch.Tensor,\n",
    "        torch.Tensor,\n",
    "        torch.Tensor,\n",
    "        torch.Tensor,\n",
    "        torch.Tensor,\n",
    "    ]:\n",
    "        mtWindows = self.windowize(waveform, self.mtWin, self.mtStep)\n",
    "        mtZCR_mean = torch.zeros(mtWindows.shape[1])\n",
    "        mtZCR_std = torch.zeros(mtWindows.shape[1])\n",
    "        energy_mean = torch.zeros(mtWindows.shape[1])\n",
    "        energy_std = torch.zeros(mtWindows.shape[1])\n",
    "        energyEntropy_mean = torch.zeros(mtWindows.shape[1])\n",
    "        energyEntropy_std = torch.zeros(mtWindows.shape[1])\n",
    "        for i in range(mtWindows.shape[1]):\n",
    "            mtWindow = mtWindows[:, i, :]\n",
    "            stWindows = self.windowize(mtWindow, self.stWin, self.stStep)\n",
    "            zcr = torch.zeros(stWindows.shape[1])\n",
    "            energy = torch.zeros(stWindows.shape[1])\n",
    "            energyEntropy = torch.zeros(stWindows.shape[1])\n",
    "            for j in range(stWindows.shape[1]):\n",
    "                stWindow = stWindows[:, j, :]\n",
    "                # Zero Crossing Rate\n",
    "                zcr[j] = (\n",
    "                    1\n",
    "                    / (2 * stWindow.shape[1])\n",
    "                    * torch.sum(torch.abs(torch.diff(torch.sign(stWindow[0, :]))))\n",
    "                )\n",
    "\n",
    "                # Energy\n",
    "                energy[j] = (1 / (len(stWindow))) * torch.sum(torch.abs(stWindow**2))\n",
    "\n",
    "                # Energy entropy\n",
    "                eps = 1e-8\n",
    "                subFramesLen = 147\n",
    "                subFrames = stWindow.reshape(1, -1, subFramesLen)\n",
    "                subFramesEnergy = (\n",
    "                    1 / subFramesLen * torch.sum(torch.abs(subFrames**2), dim=2)\n",
    "                )\n",
    "                subFramesEnergyNorm = subFramesEnergy / (\n",
    "                    torch.sum(subFramesEnergy) + eps\n",
    "                )\n",
    "                energyEntropy[j] = -torch.sum(\n",
    "                    subFramesEnergyNorm * torch.log2(subFramesEnergyNorm + eps)\n",
    "                )\n",
    "\n",
    "            mtZCR_mean[i] = torch.mean(zcr)\n",
    "            mtZCR_std[i] = torch.std(zcr)\n",
    "            energy_mean[i] = torch.mean(energy)\n",
    "            energy_std[i] = torch.std(energy)\n",
    "            energyEntropy_mean[i] = torch.mean(energyEntropy)\n",
    "            energyEntropy_std[i] = torch.std(energyEntropy)\n",
    "\n",
    "        ltZCR_mean = torch.mean(mtZCR_mean).unsqueeze(0)\n",
    "        ltZCR_std = torch.mean(mtZCR_std).unsqueeze(0)\n",
    "        ltenergy_mean = torch.mean(energy_mean).unsqueeze(0)\n",
    "        ltenergy_std = torch.mean(energy_std).unsqueeze(0)\n",
    "        ltenergyEntropy_mean = torch.mean(energyEntropy_mean).unsqueeze(0)\n",
    "        ltenergyEntropy_std = torch.mean(energyEntropy_std).unsqueeze(0)\n",
    "\n",
    "        return (\n",
    "            ltZCR_mean,\n",
    "            ltZCR_std,\n",
    "            ltenergy_mean,\n",
    "            ltenergy_std,\n",
    "            ltenergyEntropy_mean,\n",
    "            ltenergyEntropy_std,\n",
    "        )\n",
    "\n",
    "    def normalize(self, waveform: torch.Tensor) -> torch.Tensor:\n",
    "        rms = torch.sqrt(torch.mean(waveform**2))\n",
    "        waveform = waveform / rms\n",
    "        return waveform\n",
    "\n",
    "    def forward(self, waveform: torch.Tensor, sample_rate) -> torch.Tensor:\n",
    "        if waveform.shape[0] == 2:\n",
    "            waveform = self.stereo2mono(waveform)\n",
    "\n",
    "        if sample_rate != self.sample_rate:\n",
    "            self.resample.orig_freq = sample_rate\n",
    "            self.resample(waveform)\n",
    "\n",
    "        waveform = self.normalize(waveform)\n",
    "        mfcc = self.mfcc(waveform).mean(dim=2).squeeze(0)\n",
    "        timeFeatures = self.timeFeatExtraction(waveform)\n",
    "\n",
    "        features = torch.cat(\n",
    "            (\n",
    "                mfcc,\n",
    "                timeFeatures[0],\n",
    "                timeFeatures[1],\n",
    "                timeFeatures[2],\n",
    "                timeFeatures[3],\n",
    "                timeFeatures[4],\n",
    "                timeFeatures[5],\n",
    "            )\n",
    "        )\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 46\n",
    "feature_extractor = myPipeline()\n",
    "features = torch.zeros(len(df), n_features)\n",
    "for i, row in tqdm(df.iterrows()):\n",
    "    waveform, sample_rate = torchaudio.load(\n",
    "        os.path.join(data_dir, \"audio\", row[\"filename\"]), channels_first=True\n",
    "    )\n",
    "    features[i] = feature_extractor(waveform, sample_rate)\n",
    "\n",
    "# Discard first mfcc coefficient\n",
    "features = features[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Standardize Features\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "features_pca = pca.fit_transform(features)\n",
    "display(pca.explained_variance_ratio_)\n",
    "\n",
    "# Plot PCA\n",
    "plt.figure(dpi=150)\n",
    "ax = sns.scatterplot(\n",
    "    x=features_pca[:, 0],\n",
    "    y=features_pca[:, 1],\n",
    "    hue=df[\"class\"],\n",
    "    palette=\"tab10\",\n",
    "    size=0.5,\n",
    "    legend=True,\n",
    ")\n",
    "h, l = ax.get_legend_handles_labels()\n",
    "ax.legend(h[:-1], l[:-1], title=\"Class\", loc=\"upper right\", bbox_to_anchor=(1.25, 1))\n",
    "plt.title(\"PCA of features\")\n",
    "plt.xlabel(\"PCA component 1\")\n",
    "plt.ylabel(\"PCA component 2\")\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "plt.savefig(os.path.join(\"images\", \"pca.png\"), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=300, random_state=42)\n",
    "features_tsne = tsne.fit_transform(features)\n",
    "\n",
    "# Plot t-SNE\n",
    "plt.figure(dpi=150)\n",
    "ax = sns.scatterplot(\n",
    "    x=features_tsne[:, 0],\n",
    "    y=features_tsne[:, 1],\n",
    "    hue=df[\"class\"],\n",
    "    palette=\"tab10\",\n",
    "    size=0.5,\n",
    "    legend=True,\n",
    ")\n",
    "h, l = ax.get_legend_handles_labels()\n",
    "ax.legend(h[:-1], l[:-1], title=\"Class\", loc=\"upper right\", bbox_to_anchor=(1.25, 1))\n",
    "plt.title(\"t-SNE of features\")\n",
    "plt.xlabel(\"t-SNE component 1\")\n",
    "plt.ylabel(\"t-SNE component 2\")\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "plt.savefig(os.path.join(\"images\", \"tsne.png\"), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering with k-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply k-means clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(\n",
    "    n_clusters=10,\n",
    "    init=\"random\",\n",
    "    n_init=50,\n",
    "    random_state=SEED,\n",
    ")\n",
    "clusters = kmeans.fit_predict(features)\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "sns.histplot(\n",
    "    clusters,\n",
    "    discrete=True,\n",
    ")\n",
    "plt.xticks(np.arange(10))\n",
    "plt.title(\"Cluster distribution\")\n",
    "plt.xlabel(\"Clusters\")\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "plt.savefig(os.path.join(\"images\", \"cluster_distribution.png\"), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PCA with clusters\n",
    "plt.figure(dpi=150)\n",
    "ax = sns.scatterplot(\n",
    "    x=features_pca[:, 0],\n",
    "    y=features_pca[:, 1],\n",
    "    hue=clusters,\n",
    "    palette=\"tab10\",\n",
    "    legend=True,\n",
    "    size=0.5,\n",
    ")\n",
    "h, l = ax.get_legend_handles_labels()\n",
    "ax.legend(h[:-1], l[:-1], title=\"Cluster\", loc=\"upper right\", bbox_to_anchor=(1.25, 1))\n",
    "plt.title(\"PCA of features with clusters\")\n",
    "plt.xlabel(\"PCA component 1\")\n",
    "plt.ylabel(\"PCA component 2\")\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "plt.savefig(os.path.join(\"images\", \"pca_clusters.png\"), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot t-SNE with clusters\n",
    "plt.figure(dpi=150)\n",
    "ax = sns.scatterplot(\n",
    "    x=features_tsne[:, 0],\n",
    "    y=features_tsne[:, 1],\n",
    "    hue=clusters,\n",
    "    palette=\"tab10\",\n",
    "    legend=True,\n",
    "    size=0.5,\n",
    ")\n",
    "h, l = ax.get_legend_handles_labels()\n",
    "ax.legend(h[:-1], l[:-1], title=\"Cluster\", loc=\"upper right\", bbox_to_anchor=(1.25, 1))\n",
    "plt.title(\"t-SNE of features with clusters\")\n",
    "plt.xlabel(\"t-SNE component 1\")\n",
    "plt.ylabel(\"t-SNE component 2\")\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "plt.savefig(os.path.join(\"images\", \"tsne_clusters.png\"), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "\n",
    "def similarity_matrix(X):\n",
    "    dist_matrix = distance_matrix(X, X)\n",
    "    normalized_dist_matrix = dist_matrix / np.max(dist_matrix)\n",
    "    similarity_matrix = 1 - normalized_dist_matrix\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_features = features[np.argsort(clusters)]\n",
    "sim_matrix = similarity_matrix(sorted_features)\n",
    "plt.figure(dpi=150)\n",
    "sns.heatmap(sim_matrix, cmap=\"viridis\")\n",
    "plt.title(\"Similarity matrix of clusters\")\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "plt.savefig(os.path.join(\"images\", \"similarity_matrix_clusters.png\"), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_features = features[np.argsort(df[\"class\"])]\n",
    "sim_matrix = similarity_matrix(sorted_features)\n",
    "plt.figure(dpi=150)\n",
    "sns.heatmap(sim_matrix, cmap=\"viridis\")\n",
    "plt.title(\"Similarity matrix of classes\")\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "plt.savefig(os.path.join(\"images\", \"similarity_matrix_class.png\"), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = features\n",
    "y = df[\"class\"].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=SEED, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "dummy = DummyClassifier(strategy=\"uniform\", random_state=SEED)\n",
    "y_pred = dummy.fit(X_train, y_train).predict(X_test)\n",
    "clf_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "dummy_acc = round(clf_report[\"accuracy\"], 2)\n",
    "dummy_f1 = round(clf_report[\"macro avg\"][\"f1-score\"], 2)\n",
    "dummy_precision = round(clf_report[\"macro avg\"][\"precision\"], 2)\n",
    "dummy_recall = round(clf_report[\"macro avg\"][\"recall\"], 2)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True)\n",
    "plt.title(\"Confusion matrix - Dummy\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "plt.savefig(os.path.join(\"images\", \"confusion_matrix_dummy.png\"), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a knn classifier on the features with onevsrest strategy\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "param_range = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25]\n",
    "train_scores, test_scores = validation_curve(\n",
    "    KNeighborsClassifier(),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    param_name=\"n_neighbors\",\n",
    "    param_range=param_range,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    ")\n",
    "\n",
    "# Calculate mean and standard deviation of training scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "\n",
    "# Calculate mean and standard deviation of test scores\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Plot validation curve\n",
    "plt.figure(dpi=150)\n",
    "plt.plot(\n",
    "    param_range,\n",
    "    train_mean,\n",
    "    label=\"Training score\",\n",
    "    color=\"blue\",\n",
    "    marker=\"o\",\n",
    "    markersize=3,\n",
    ")\n",
    "plt.fill_between(\n",
    "    param_range,\n",
    "    train_mean - train_std,\n",
    "    train_mean + train_std,\n",
    "    alpha=0.1,\n",
    "    color=\"blue\",\n",
    ")\n",
    "plt.plot(\n",
    "    param_range,\n",
    "    test_mean,\n",
    "    label=\"Cross-validation score\",\n",
    "    color=\"red\",\n",
    "    marker=\"o\",\n",
    "    markersize=3,\n",
    ")\n",
    "plt.fill_between(\n",
    "    param_range,\n",
    "    test_mean - test_std,\n",
    "    test_mean + test_std,\n",
    "    alpha=0.1,\n",
    "    color=\"red\",\n",
    ")\n",
    "plt.title(\"Validation Curve\")\n",
    "plt.xlabel(\"Number of Neighbors\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"best\")\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "plt.savefig(os.path.join(\"images\", \"knn_validation_curve.png\"), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a knn classifier with found hyperparameter\n",
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "clf_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "knn_acc = round(clf_report[\"accuracy\"], 2)\n",
    "knn_f1 = round(clf_report[\"macro avg\"][\"f1-score\"], 2)\n",
    "knn_precision = round(clf_report[\"macro avg\"][\"precision\"], 2)\n",
    "knn_recall = round(clf_report[\"macro avg\"][\"recall\"], 2)\n",
    "knn_class_f1 = [round(clf_report[str(c)][\"f1-score\"], 2) for c in range(0, 10)]\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(dpi=150)\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True)\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title(\"Confusion matrix - KNN\")\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "plt.savefig(os.path.join(\"images\", \"confusion_matrix_knn.png\"), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "    \"gamma\": [0.01, 0.1, 1, 10, 100],\n",
    "    \"kernel\": [\"rbf\", \"poly\", \"sigmoid\"],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, refit=True, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "clf_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "svm_acc = round(clf_report[\"accuracy\"], 2)\n",
    "svm_f1 = round(clf_report[\"macro avg\"][\"f1-score\"], 2)\n",
    "svm_precision = round(clf_report[\"macro avg\"][\"precision\"], 2)\n",
    "svm_recall = round(clf_report[\"macro avg\"][\"recall\"], 2)\n",
    "svm_class_f1 = [round(clf_report[str(c)][\"f1-score\"], 2) for c in range(0, 10)]\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True)\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title(\"Confusion matrix - SVM\")\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "plt.savefig(os.path.join(\"images\", \"confusion_matrix_svm.png\"), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "param_grid = {\n",
    "    \"hidden_layer_sizes\": [(80), (80, 50), (80, 50, 50)],\n",
    "    \"learning_rate_init\": [0.01, 0.001],\n",
    "    \"solver\": [\"adam\", \"sgd\"],\n",
    "    \"activation\": [\"relu\", \"tanh\"],\n",
    "    \"alpha\": [0.0001, 0.001, 0.01],\n",
    "    \"batch_size\": [32, 64],\n",
    "}\n",
    "\n",
    "clf = MLPClassifier(\n",
    "    max_iter=5000,\n",
    "    n_iter_no_change=10,\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    clf, param_grid, refit=True, cv=5, scoring=\"accuracy\", n_jobs=-1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "pd.DataFrame(grid_search.cv_results_).to_csv(\"mlp_grid_search.csv\", index=False)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "clf_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "mlp_acc = round(clf_report[\"accuracy\"], 2)\n",
    "mlp_f1 = round(clf_report[\"macro avg\"][\"f1-score\"], 2)\n",
    "mlp_precision = round(clf_report[\"macro avg\"][\"precision\"], 2)\n",
    "mlp_recall = round(clf_report[\"macro avg\"][\"recall\"], 2)\n",
    "mlp_class_f1 = [round(clf_report[str(c)][\"f1-score\"], 2) for c in range(0, 10)]\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True)\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title(\"Confusion matrix - MLP\")\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "plt.savefig(os.path.join(\"images\", \"confusion_matrix_mlp.png\"), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500],\n",
    "    \"max_depth\": [10, 20, 30, 40, 50],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "}\n",
    "\n",
    "clf = RandomForestClassifier(random_state=SEED)\n",
    "grid_search = GridSearchCV(clf, param_grid, refit=True, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "clf_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "rf_acc = round(clf_report[\"accuracy\"], 2)\n",
    "rf_f1 = round(clf_report[\"macro avg\"][\"f1-score\"], 2)\n",
    "rf_precision = round(clf_report[\"macro avg\"][\"precision\"], 2)\n",
    "rf_recall = round(clf_report[\"macro avg\"][\"recall\"], 2)\n",
    "rf_class_f1 = [round(clf_report[str(c)][\"f1-score\"], 2) for c in range(0, 10)]\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True)\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title(\"Confusion matrix - Random Forest\")\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "plt.savefig(os.path.join(\"images\", \"confusion_matrix_rf.png\"), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Model\": [\"Dummy\", \"KNN\", \"SVM\", \"MLP\", \"Random Forest\"],\n",
    "    \"Accuracy\": [dummy_acc, knn_acc, svm_acc, mlp_acc, rf_acc],\n",
    "    \"Precision\": [\n",
    "        dummy_precision,\n",
    "        knn_precision,\n",
    "        svm_precision,\n",
    "        mlp_precision,\n",
    "        rf_precision,\n",
    "    ],\n",
    "    \"Recall\": [dummy_recall, knn_recall, svm_recall, mlp_recall, rf_recall],\n",
    "    \"F1-score\": [dummy_f1, knn_f1, svm_f1, mlp_f1, rf_f1],\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"results.csv\", index=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(dpi=150)\n",
    "sns.barplot(x=\"Model\", y=\"Accuracy\", data=results_df)\n",
    "plt.title(\"Model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "plt.savefig(os.path.join(\"images\", \"model_accuracy.png\"), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "sns.barplot(x=\"Model\", y=\"Precision\", data=results_df)\n",
    "plt.title(\"Model precision\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "plt.savefig(os.path.join(\"images\", \"model_precision.png\"), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "sns.barplot(x=\"Model\", y=\"Recall\", data=results_df)\n",
    "plt.title(\"Model recall\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "plt.savefig(os.path.join(\"images\", \"model_recall.png\"), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "sns.barplot(x=\"Model\", y=\"F1-score\", data=results_df)\n",
    "plt.title(\"Model F1-score\")\n",
    "plt.ylabel(\"F1\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "plt.savefig(os.path.join(\"images\", \"model_f1.png\"), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Model\": [\n",
    "        \"KNN\",\n",
    "        \"KNN\",\n",
    "        \"KNN\",\n",
    "        \"KNN\",\n",
    "        \"KNN\",\n",
    "        \"KNN\",\n",
    "        \"KNN\",\n",
    "        \"KNN\",\n",
    "        \"KNN\",\n",
    "        \"KNN\",\n",
    "        \"SVM\",\n",
    "        \"SVM\",\n",
    "        \"SVM\",\n",
    "        \"SVM\",\n",
    "        \"SVM\",\n",
    "        \"SVM\",\n",
    "        \"SVM\",\n",
    "        \"SVM\",\n",
    "        \"SVM\",\n",
    "        \"SVM\",\n",
    "        \"MLP\",\n",
    "        \"MLP\",\n",
    "        \"MLP\",\n",
    "        \"MLP\",\n",
    "        \"MLP\",\n",
    "        \"MLP\",\n",
    "        \"MLP\",\n",
    "        \"MLP\",\n",
    "        \"MLP\",\n",
    "        \"MLP\",\n",
    "        \"Random Forest\",\n",
    "        \"Random Forest\",\n",
    "        \"Random Forest\",\n",
    "        \"Random Forest\",\n",
    "        \"Random Forest\",\n",
    "        \"Random Forest\",\n",
    "        \"Random Forest\",\n",
    "        \"Random Forest\",\n",
    "        \"Random Forest\",\n",
    "        \"Random Forest\",\n",
    "    ],\n",
    "    \"Class\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] * 4,\n",
    "    \"F1-score\": [\n",
    "        *knn_class_f1,\n",
    "        *svm_class_f1,\n",
    "        *mlp_class_f1,\n",
    "        *rf_class_f1,\n",
    "    ],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"class_results.csv\", index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class results\n",
    "plt.figure(dpi=150)\n",
    "ax = sns.barplot(x=\"Class\", y=\"F1-score\", hue=\"Model\", data=df)\n",
    "h, l = ax.get_legend_handles_labels()\n",
    "ax.legend(h, l, title=\"Model\", loc=\"upper right\", bbox_to_anchor=(1.57, 1))\n",
    "plt.title(\"Class F1-score\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.ylim(0, 1)\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "plt.savefig(os.path.join(\"images\", \"class_f1.png\"), dpi=150)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
